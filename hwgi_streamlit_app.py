import streamlit as st

# ê¸°ë³¸ ì„¤ì • - ë°˜ë“œì‹œ ë‹¤ë¥¸ st ëª…ë ¹ì–´ë³´ë‹¤ ë¨¼ì € í˜¸ì¶œí•´ì•¼ í•¨
st.set_page_config(
    page_title="í•œí™”ì†í•´ë³´í—˜ ì‚¬ì—…ë³´ê³ ì„œ RAG ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

import subprocess
import os
import sys
import glob
import json
import time
import threading
import pandas as pd
from datetime import datetime
import tempfile
import re
import langsmith
from langsmith import Client
from langsmith.run_helpers import traceable
import uuid
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# LangSmith í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "hwgi_rag_streamlit"  # í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •

# LangSmith í´ë¼ì´ì–¸íŠ¸ ì„¤ì • - st.sidebar í˜¸ì¶œì„ ë‚˜ì¤‘ì— ìˆ˜í–‰
try:
    langsmith_client = Client()
    langsmith_enabled = True
    # ì—¬ê¸°ì„œ st.sidebar í˜¸ì¶œ ì œê±°
except Exception as e:
    langsmith_enabled = False
    print(f"LangSmith ì—°ê²° ì‹¤íŒ¨: {e}")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'auto_test_results' not in st.session_state:
    st.session_state.auto_test_results = None
if 'last_question' not in st.session_state:
    st.session_state.last_question = ""
if 'last_answer' not in st.session_state:
    st.session_state.last_answer = {}
if 'backend_initialized' not in st.session_state:
    st.session_state.backend_initialized = False
if 'backend_process' not in st.session_state:
    st.session_state.backend_process = None
if 'multi_queries' not in st.session_state:
    st.session_state.multi_queries = []
if 'doc_summaries' not in st.session_state:
    st.session_state.doc_summaries = []
if 'original_query' not in st.session_state:
    st.session_state.original_query = ""
if 'raw_output' not in st.session_state:
    st.session_state.raw_output = ""
if 'auto_test_log' not in st.session_state:
    st.session_state.auto_test_log = ""
if 'run_ids' not in st.session_state:
    st.session_state.run_ids = {}

# ë”ë¯¸ traceable ë°ì½”ë ˆì´í„° í•¨ìˆ˜ ì •ì˜ (LangSmith ë¹„í™œì„±í™” ì‹œ ì‚¬ìš©)
def dummy_traceable(*args, **kwargs):
    # í•¨ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ëŠ” ë°ì½”ë ˆì´í„°
    def decorator(func):
        return func
    # run_type ì¸ìê°€ ì§ì ‘ ì „ë‹¬ëœ ê²½ìš°
    if len(args) == 1 and callable(args[0]):
        return args[0]
    return decorator

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (API í‚¤ ìœ ì§€ë¥¼ ìœ„í•´)
if 'langsmith_api_key' not in st.session_state:
    st.session_state.langsmith_api_key = os.environ.get("LANGCHAIN_API_KEY", "")
    
# LangSmith í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: ë¹„í™œì„±í™”)
if 'enable_langsmith' not in st.session_state:
    st.session_state.enable_langsmith = False
    
# langsmith_error_occurred í”Œë˜ê·¸ ì´ˆê¸°í™”
if 'langsmith_error_occurred' not in st.session_state:
    st.session_state.langsmith_error_occurred = False

# LangSmith í™˜ê²½ ë³€ìˆ˜ í™•ì¸
langsmith_api_key = st.session_state.langsmith_api_key
traceable = dummy_traceable  # ê¸°ë³¸ê°’ìœ¼ë¡œ ë”ë¯¸ í•¨ìˆ˜ ì‚¬ìš©

# PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_pdf_files():
    pdf_files = glob.glob("*.pdf")
    return pdf_files

# ì¿¼ë¦¬ ê²°ê³¼ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
def get_query_results_files():
    if os.path.exists("query_results"):
        files = glob.glob("query_results/query_*.json")
        return sorted(files, key=os.path.getmtime, reverse=True)  # ìµœì‹  íŒŒì¼ ìˆœìœ¼ë¡œ ì •ë ¬
    return []

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ“Š í•œí™”ì†í•´ë³´í—˜ RAG ì‹œìŠ¤í…œ")
# st.subheader("(Local ëª¨ë¸ ë¹„êµ: Llama3.1:8b vs Gemma3:4b)")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ í™˜ê²½ ì„¤ì •")

# LangSmith ì—°ê²° ìƒíƒœë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ (ì´ê³³ìœ¼ë¡œ ì´ë™)
if langsmith_enabled:
    st.sidebar.success("âœ… LangSmith ì—°ê²°ë¨")
else:
    st.sidebar.warning("âš ï¸ LangSmith ì—°ê²° ì‹¤íŒ¨")

# PDF íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.sidebar.file_uploader(
    "PDF íŒŒì¼ ì—…ë¡œë“œ",
    type=["pdf"],
    help="ë¶„ì„í•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. íŒŒì¼ì€ ì„œë²„ì— ì„ì‹œë¡œ ì €ì¥ë©ë‹ˆë‹¤."
)

# ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬
selected_pdf = None
if uploaded_file is not None:
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    if not uploaded_file.name.lower().endswith('.pdf'):
        st.sidebar.error("âŒ PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "temp_uploads")
        os.makedirs(temp_dir, exist_ok=True)
        
        # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        temp_pdf_path = os.path.join(temp_dir, f"{timestamp}_{uploaded_file.name}")
        
        with open(temp_pdf_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        selected_pdf = temp_pdf_path
        st.sidebar.success(f"âœ… '{uploaded_file.name}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    # ê¸°ì¡´ PDF íŒŒì¼ ëª©ë¡ (ì—…ë¡œë“œê°€ ì—†ì„ ê²½ìš° ì„ íƒ ê°€ëŠ¥)
    pdf_files = get_pdf_files()
    if not pdf_files:
        st.sidebar.warning("âš ï¸ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í”„ë¡œê·¸ë¨ ë””ë ‰í† ë¦¬ì— PDFë¥¼, ì €ì¥í•´ ì£¼ì„¸ìš”.")
        selected_pdf = None
    else:
        default_pdf = st.sidebar.selectbox(
            "ë˜ëŠ” ê¸°ì¡´ PDF íŒŒì¼ ì„ íƒ",
            options=pdf_files,
            index=0
        )
        selected_pdf = default_pdf
        st.sidebar.info(f"ğŸ“„ ì„ íƒëœ PDF íŒŒì¼: {os.path.basename(selected_pdf)}")

# ì²­í¬ í¬ê¸° ë° ê²¹ì¹¨ ì„¤ì •
chunk_size = st.sidebar.slider("ì²­í¬ í¬ê¸°", min_value=100, max_value=1000, value=500, step=50)
chunk_overlap = st.sidebar.slider("ì²­í¬ ê²¹ì¹¨", min_value=50, max_value=300, value=150, step=25)

# ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •
top_k = st.sidebar.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (Top-K)", min_value=3, max_value=20, value=10)

# ì¸ë±ìŠ¤ ê°•ì œ ì—…ë°ì´íŠ¸ ì˜µì…˜ (ì²´í¬ë°•ìŠ¤ëŠ” ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì„¤ì •)
force_update = st.sidebar.checkbox("ë²¡í„° ì¸ë±ìŠ¤ ê°•ì œ ì—…ë°ì´íŠ¸", value=False)
# force_update = False

# HNSW ì¸ë±ìŠ¤ ì‚¬ìš© ì˜µì…˜ (ì²´í¬ë°•ìŠ¤ëŠ” ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì„¤ì •)
# use_hnsw = st.sidebar.checkbox("HNSW ì¸ë±ìŠ¤ ì‚¬ìš© (ì •í™•ë„ í–¥ìƒ)", value=True)
use_hnsw = True

# ìë™ í‰ê°€ ì˜µì…˜ (ì²´í¬ë°•ìŠ¤ëŠ” ì œê±°í•˜ê³  ê¸°ë³¸ê°’ ì„¤ì •)
# auto_eval = st.sidebar.checkbox("ìë™ í‰ê°€ í™œì„±í™” (gemma3:12b í•„ìš”)", value=True)
auto_eval = True

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì§ˆë¬¸ ì‘ë‹µ", "ğŸ”„ ìë™ í…ŒìŠ¤íŠ¸", "ğŸ” ë””ë²„ê·¸"])

# LangSmithë¡œ ì¶”ì í•˜ëŠ” í•¨ìˆ˜
@traceable(name="extract_info")
def extract_multi_queries_and_docs(output):
    multi_queries = []
    doc_summaries = []
    original_query = ""
    
    # ì›ë³¸ ì¿¼ë¦¬ ì¶”ì¶œ
    original_query_pattern = r"(?:ğŸ’¬ ì§ˆë¬¸:|ì›ë³¸ ì§ˆë¬¸:)\s*(.*?)(?:\n|$)"
    original_query_match = re.search(original_query_pattern, output)
    if original_query_match:
        original_query = original_query_match.group(1).strip()
    
    # ë©€í‹°ì¿¼ë¦¬ ì¶”ì¶œ (íŒ¨í„´ ê°•í™”)
    multi_query_sections = [
        r"ğŸ”„ í™•ì¥ ì§ˆì˜:\s*\n(.*?)(?=\n\n|\nğŸ”|\nğŸ’¡)",
        r"ë©€í‹°ì¿¼ë¦¬ ìƒì„± ê²°ê³¼:\s*\n(.*?)(?=\n\n|\nğŸ”|\nğŸ’¡)",
        r"ë©€í‹°ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼:\s*\n(.*?)(?=\n\n|\nğŸ”|\nğŸ’¡)",
        r"ìƒì„±ëœ ì¿¼ë¦¬:\s*\n(.*?)(?=\n\n|\nğŸ”|\nğŸ’¡)",
    ]
    
    # ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„
    for pattern in multi_query_sections:
        multi_query_match = re.search(pattern, output, re.DOTALL)
        if multi_query_match:
            query_text = multi_query_match.group(1).strip()
            for line in query_text.split('\n'):
                clean_line = line.strip()
                if clean_line.startswith('- '):
                    multi_queries.append(clean_line[2:])  # '- ' ì œê±°
                elif clean_line and not clean_line.startswith('#') and not clean_line.startswith('=='):  
                    # '#'ì´ë‚˜ '=='ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ë¹„ì–´ìˆì§€ ì•Šì€ ë¼ì¸
                    multi_queries.append(clean_line)
    
    # ë¬¸ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ
    docs_pattern = r"ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì¤‘\.\.\.[\s\S]*?(í˜ì´ì§€.*?)(?:\n\n|\nğŸ’¡)"
    docs_match = re.search(docs_pattern, output, re.DOTALL)
    if docs_match:
        doc_text = docs_match.group(1)
        doc_lines = [line.strip() for line in doc_text.split('\n') if line.strip()]
        doc_summaries = doc_lines
    
    return original_query, multi_queries, doc_summaries

# LangSmithë¡œ ì¶”ì í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
@traceable(name="process_question", run_type="chain")
def process_question_with_file(question, pdf_path, chunk_size, chunk_overlap, top_k, force_update, use_hnsw, auto_eval):
    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as temp_file:
        temp_file.write(question)
        temp_file_path = temp_file.name
    
    try:
        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ í”Œë˜ê·¸ ì„¤ì •
        st.session_state.process_running = True
        st.session_state.raw_output = "ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘ ì¤‘...\n"
        
        # ëª…ë ¹ì–´ êµ¬ì„±
        cmd = [
            "python3", "hwgi_rag_auto.py",
            "--pdf", pdf_path,
            "--chunk-size", str(chunk_size),
            "--chunk-overlap", str(chunk_overlap),
            "--top-k", str(top_k)
        ]
        
        # ì¶”ê°€ ì˜µì…˜
        if force_update:
            cmd.append("--force-update")
        if not use_hnsw:
            cmd.append("--flat-index")
        if auto_eval:
            cmd.append("--auto-eval")
        
        # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        cmd_str = ' '.join(cmd)
        print(f"ì‹¤í–‰ ëª…ë ¹ì–´: {cmd_str}")
        st.session_state.raw_output += f"ì‹¤í–‰ ëª…ë ¹ì–´: {cmd_str}\n\n"
        st.session_state.raw_output += "ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...\n"
        
        # íŒŒì¼ì—ì„œ ì§ˆë¬¸ ì½ê¸° ìœ„í•œ ì…ë ¥ ë¦¬ë””ë ‰ì…˜ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
        # ì´ë ‡ê²Œ í•˜ë©´ ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì§ˆë¬¸ì„ ì „ë‹¬í•˜ì§€ ì•Šì•„ ê³µë°± ë¬¸ì œë¥¼ í”¼í•  ìˆ˜ ìˆìŒ
        with open(temp_file_path, 'r') as input_file:
            result = subprocess.run(
                cmd,
                stdin=input_file,
                capture_output=True,
                text=True,
                timeout=300
            )
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶œë ¥ (stderrê°€ ìˆëŠ” ê²½ìš°ë§Œ)
            if result.stderr:
                print(f"í•˜ìœ„ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜ ì¶œë ¥: {result.stderr}")
                st.session_state.raw_output += f"\nì˜¤ë¥˜ ì¶œë ¥:\n{result.stderr}\n"
            
            # í‘œì¤€ ì¶œë ¥ ì¶”ê°€
            if result.stdout:
                st.session_state.raw_output += f"\nëª…ë ¹ ì¶œë ¥:\n{result.stdout}\n"
            
            # ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€ ì¶”ê°€
            if result.returncode == 0:
                st.session_state.raw_output += "\nâœ… í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì™„ë£Œ\n"
            else:
                st.session_state.raw_output += f"\nâŒ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨ (ì¢…ë£Œ ì½”ë“œ: {result.returncode})\n"
                
        return result
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(temp_file_path):
            os.unlink(temp_file_path)
        # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì •
        st.session_state.process_running = False

# ì§ˆë¬¸ ì‘ë‹µ íƒ­
with tab1:
    st.header("ì§ˆë¬¸ ì‘ë‹µ")
    
    # ì €ì¥ëœ ì¿¼ë¦¬ ê²°ê³¼ í™•ì¸ ì˜µì…˜ ì¶”ê°€
    query_results_files = get_query_results_files()
    if query_results_files:
        st.subheader("ğŸ“ ì €ì¥ëœ ì¿¼ë¦¬ ê²°ê³¼")
        selected_result_file = st.selectbox(
            "ì´ì „ ì¿¼ë¦¬ ê²°ê³¼ ì„ íƒ",
            options=["ìƒˆ ì¿¼ë¦¬ ì…ë ¥"] + query_results_files,
            format_func=lambda x: f"ìƒˆ ì¿¼ë¦¬ ì…ë ¥" if x == "ìƒˆ ì¿¼ë¦¬ ì…ë ¥" else f"{os.path.basename(x)} - {time.ctime(os.path.getmtime(x))}"
        )
        
        # ì´ì „ ì¿¼ë¦¬ ê²°ê³¼ ë¡œë“œ
        if selected_result_file != "ìƒˆ ì¿¼ë¦¬ ì…ë ¥":
            try:
                with open(selected_result_file, 'r', encoding='utf-8') as f:
                    query_data = json.load(f)
                
                # ë°ì´í„° í‘œì‹œ
                st.subheader(f"ì§ˆë¬¸: {query_data['query']}")
                st.caption(f"ìƒì„± ì‹œê°„: {query_data['timestamp']}")
                
                # ë©€í‹°ì¿¼ë¦¬ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                if 'context' in query_data:
                    with st.expander("ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸", expanded=False):
                        st.markdown(query_data['context'])
                
                # ê° ëª¨ë¸ì˜ ì‘ë‹µ í‘œì‹œ
                if 'results' in query_data:
                    for model, answer in query_data['results'].items():
                        with st.expander(f"ğŸ“ ëª¨ë¸: {model}", expanded=True):
                            st.markdown(answer)
                            
                            # ìë™ í‰ê°€ ê²°ê³¼ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                            if query_data.get('auto_evaluations') and model in query_data['auto_evaluations']:
                                eval_data = query_data['auto_evaluations'][model]
                                score = eval_data.get('score')
                                reason = eval_data.get('reason', 'í‰ê°€ ì •ë³´ ì—†ìŒ')
                                
                                st.divider()
                                st.markdown("**ğŸ¤– ìë™ í‰ê°€ ê²°ê³¼:**")
                                if score is not None:
                                    st.markdown(f"**ì ìˆ˜**: {score}/5")
                                st.markdown(f"**í‰ê°€ ì´ìœ **: {reason}")
            except Exception as e:
                st.error(f"ì¿¼ë¦¬ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ìƒˆ ì¿¼ë¦¬ ì…ë ¥ì´ ì„ íƒë˜ì—ˆê±°ë‚˜ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì…ë ¥ í¼ í‘œì‹œ
    if not query_results_files or selected_result_file == "ìƒˆ ì¿¼ë¦¬ ì…ë ¥":
        # ì§ˆë¬¸ ì…ë ¥
        question = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", height=100, value=st.session_state.last_question)
        
        if st.button("ì§ˆë¬¸ ì œì¶œ", type="primary", disabled=(not selected_pdf)):
            if question:
                st.session_state.last_question = question
                
                with st.spinner("ì§ˆë¬¸ì— ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # LangSmith ì¶”ì ì„ ìœ„í•œ ê³ ìœ  ID ìƒì„±
                        run_id = None
                        if langsmith_enabled:
                            try:
                                run_id = str(uuid.uuid4())
                                st.session_state.run_ids['last_query'] = run_id
                                
                                # LangSmith ë©”íƒ€ë°ì´í„° ì„¤ì •
                                langsmith_client.create_run(
                                    name="ì§ˆë¬¸ ì‘ë‹µ ì‹œì‘",
                                    run_type="chain",
                                    inputs={"query": question, "pdf": selected_pdf},
                                    run_id=run_id
                                )
                            except Exception as e:
                                st.warning(f"LangSmith ì¶”ì  í™œì„±í™” ì‹¤íŒ¨ (ì˜í–¥ ì—†ìŒ): {str(e)}")
                                print(f"LangSmith ì¶”ì  ì˜¤ë¥˜: {e}")
                                langsmith_enabled = False
                        
                        # íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ì²˜ë¦¬
                        result = process_question_with_file(
                            question,
                            selected_pdf,
                            chunk_size,
                            chunk_overlap,
                            top_k,
                            force_update,
                            use_hnsw,
                            auto_eval
                        )
                        
                        # ê²°ê³¼ ì²˜ë¦¬
                        if result.returncode == 0:
                            output = result.stdout
                            # ë””ë²„ê¹…ì„ ìœ„í•´ ì›ë³¸ ì¶œë ¥ ì €ì¥
                            st.session_state.raw_output = output
                            
                            # ì›ë³¸ ì¿¼ë¦¬, ë©€í‹°ì¿¼ë¦¬ì™€ ë¬¸ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ
                            original_query, multi_queries, doc_summaries = extract_multi_queries_and_docs(output)
                            st.session_state.original_query = original_query
                            st.session_state.multi_queries = multi_queries
                            st.session_state.doc_summaries = doc_summaries
                            
                            # ì‘ë‹µ íŒŒì‹± (ê° ëª¨ë¸ë³„ ì‘ë‹µ ì„¹ì…˜ ì¶”ì¶œ)
                            model_answers = {}
                            current_model = None
                            answer_text = ""
                            
                            for line in output.split('\n'):
                                if line.startswith("ğŸ“ ëª¨ë¸:"):
                                    if current_model and answer_text:
                                        model_answers[current_model] = answer_text.strip()
                                    current_model = line.replace("ğŸ“ ëª¨ë¸:", "").strip()
                                    answer_text = ""
                                elif current_model and not line.startswith("â”€") and not line.startswith("ğŸ¤–"):
                                    answer_text += line + "\n"
                            
                            # ë§ˆì§€ë§‰ ëª¨ë¸ ì‘ë‹µ ì €ì¥
                            if current_model and answer_text:
                                model_answers[current_model] = answer_text.strip()
                            
                            st.session_state.last_answer = model_answers
                            
                            # LangSmithì— ê²°ê³¼ ê¸°ë¡
                            if langsmith_enabled:
                                langsmith_client.update_run(
                                    run_id=run_id,
                                    outputs={
                                        "model_answers": model_answers,
                                        "multi_queries": multi_queries,
                                        "doc_summaries": doc_summaries
                                    },
                                    end_time=datetime.utcnow(),
                                    error=None
                                )
                        else:
                            st.error("ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨:")
                            st.code(result.stderr)
                            st.code(result.stdout)
                            
                            # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                            if langsmith_enabled:
                                langsmith_client.update_run(
                                    run_id=run_id,
                                    outputs=None,
                                    end_time=datetime.utcnow(),
                                    error=result.stderr
                                )
                        
                        # ë¡œê·¸ í‘œì‹œ
                        # if result.stderr:
                        #     st.error("ì˜¤ë¥˜ ë°œìƒ:")
                        #     st.code(result.stderr)
                    
                    except subprocess.TimeoutExpired as e:
                        st.warning("ì‹¤í–‰ ì‹œê°„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ê°€ ê³„ì† ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                        if langsmith_enabled and 'run_id' in locals():
                            langsmith_client.update_run(
                                run_id=run_id,
                                outputs=None,
                                end_time=datetime.utcnow(),
                                error=str(e)
                            )
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                        if langsmith_enabled and 'run_id' in locals():
                            langsmith_client.update_run(
                                run_id=run_id,
                                outputs=None,
                                end_time=datetime.utcnow(),
                                error=str(e)
                            )
    
    # ì›ë³¸ ì¿¼ë¦¬ì™€ ë©€í‹°ì¿¼ë¦¬ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ì— í‘œì‹œ
    if st.session_state.multi_queries:
        with st.expander("ğŸ”„ ê²€ìƒ‰ ì¿¼ë¦¬ (Query Generation)", expanded=True):
            # ì›ë³¸ ì¿¼ë¦¬ í‘œì‹œ
            if st.session_state.original_query:
                st.markdown(f"**ì›ë³¸ ì§ˆë¬¸**: {st.session_state.original_query}")
            
            # êµ¬ë¶„ì„  ì¶”ê°€
            st.markdown("---")
            
            # ë©€í‹°ì¿¼ë¦¬ í‘œì‹œ
            st.markdown("**ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬**:")
            
            # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            query_data = []
            for i, query in enumerate(st.session_state.multi_queries):
                query_data.append({
                    "ë²ˆí˜¸": i+1,
                    "ê²€ìƒ‰ ì¿¼ë¦¬": query
                })
            
            if query_data:
                st.table(pd.DataFrame(query_data))
    
    # ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìš” í‘œì‹œ
    if st.session_state.doc_summaries:
        with st.expander("ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìš”", expanded=False):
            for doc in st.session_state.doc_summaries:
                st.markdown(f"- {doc}")
    
    # ëª¨ë¸ ì‘ë‹µ í‘œì‹œ
    if st.session_state.last_answer:
        st.subheader(f"ì§ˆë¬¸: {st.session_state.last_question}")
        
        for model, answer in st.session_state.last_answer.items():
            with st.expander(f"ğŸ“ ëª¨ë¸: {model}", expanded=True):
                st.markdown(answer)
    
    # ë¡œê·¸ í‘œì‹œ ì˜ì—­ ì¶”ê°€
    if st.session_state.raw_output:
        with st.expander("ğŸ”„ ì‹¤í–‰ ë¡œê·¸", expanded=True):
            st.code(st.session_state.raw_output)
            
    # ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
    status_container = st.empty()
    if 'process_running' not in st.session_state:
        st.session_state.process_running = False
    
    if st.session_state.process_running:
        status_container.info("ğŸ’¬ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘... ìœ„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        status_container.empty()

# ìë™ í…ŒìŠ¤íŠ¸ íƒ­
with tab2:
    st.header("ìë™ í…ŒìŠ¤íŠ¸")
    
    col1, col2 = st.columns(2)
    with col1:
        num_questions = st.number_input("ìƒì„±í•  ì§ˆë¬¸ ìˆ˜", min_value=1, max_value=20, value=5)
    
    if st.button("ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰", disabled=(not selected_pdf)):
        # LangSmith ì¶”ì ì„ ìœ„í•œ ê³ ìœ  ID ìƒì„±
        auto_test_run_id = str(uuid.uuid4())
        st.session_state.run_ids['auto_test'] = auto_test_run_id
        
        # LangSmith ë©”íƒ€ë°ì´í„° ì„¤ì •
        if langsmith_enabled:
            langsmith_client.create_run(
                name="ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰",
                run_type="chain",
                inputs={"pdf": selected_pdf, "num_questions": num_questions},
                run_id=auto_test_run_id
            )
            
        # ëª…ë ¹ì–´ êµ¬ì„±
        cmd = [
            "python3", "hwgi_rag_auto.py",
            "--pdf", selected_pdf,
            "--chunk-size", str(chunk_size),
            "--chunk-overlap", str(chunk_overlap),
            "--top-k", str(top_k),
            "--auto-test"
        ]
        
        # ìë™ í‰ê°€ ì˜µì…˜ ì¶”ê°€ 
        if auto_eval:
            cmd.append("--auto-eval")
        
        # ì¶”ê°€ ì˜µì…˜
        cmd.extend(["--num-questions", str(num_questions)])
        if force_update:
            cmd.append("--force-update")
        if not use_hnsw:
            cmd.append("--flat-index")
        
        with st.spinner(f"{num_questions}ê°œì˜ ìë™ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ìƒì„± ë° í‰ê°€ ì¤‘..."):
            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=600  # ìë™ í…ŒìŠ¤íŠ¸ëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ í—ˆìš©
                )
                
                # ë¡œê·¸ ì €ì¥
                st.session_state.auto_test_log = result.stdout
                
                # ê°€ì¥ ìµœê·¼ ìë™ í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
                auto_test_files = glob.glob("auto_test_results_*.json")
                if auto_test_files:
                    latest_file = max(auto_test_files, key=os.path.getctime)
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        st.session_state.auto_test_results = json.load(f)
                    
                    # LangSmithì— ê²°ê³¼ ê¸°ë¡
                    if langsmith_enabled:
                        langsmith_client.update_run(
                            run_id=auto_test_run_id,
                            outputs={"results": st.session_state.auto_test_results},
                            end_time=datetime.utcnow(),
                            error=None
                        )
                
                # ë¡œê·¸ í‘œì‹œ
                if result.stderr:
                    st.error("ì˜¤ë¥˜ ë°œìƒ:")
                    st.code(result.stderr)
                    
                    # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                    if langsmith_enabled:
                        langsmith_client.update_run(
                            run_id=auto_test_run_id,
                            outputs=None,
                            end_time=datetime.utcnow(),
                            error=result.stderr
                        )
            
            except subprocess.TimeoutExpired as e:
                st.warning("ì‹¤í–‰ ì‹œê°„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ê°€ ê³„ì† ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                if langsmith_enabled:
                    langsmith_client.update_run(
                        run_id=auto_test_run_id,
                        outputs=None,
                        end_time=datetime.utcnow(),
                        error=str(e)
                    )
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # LangSmithì— ì˜¤ë¥˜ ê¸°ë¡
                if langsmith_enabled:
                    langsmith_client.update_run(
                        run_id=auto_test_run_id,
                        outputs=None,
                        end_time=datetime.utcnow(),
                        error=str(e)
                    )
    
    # ìë™ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ
    if st.session_state.auto_test_results:
        st.subheader("ìë™ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        
        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        results = st.session_state.auto_test_results
        
        # ì§ˆë¬¸ ëª©ë¡ í‘œì‹œ
        if "tests" in results:
            for i, test in enumerate(results.get("tests", [])):
                with st.expander(f"ì§ˆë¬¸ {i+1}: {test.get('question')}", expanded=i==0):
                    # contextê°€ Noneì¸ ê²½ìš° ì˜¤ë¥˜ ë°©ì§€
                    context = test.get('context')
                    if context:
                        st.markdown(f"**ì»¨í…ìŠ¤íŠ¸**: {context[:500]}...")
                    else:
                        st.markdown("**ì»¨í…ìŠ¤íŠ¸**: ì»¨í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    # ëª¨ë¸ë³„ ì‘ë‹µ í‘œì‹œ
                    if "responses" in test:
                        for model, response in test.get("responses", {}).items():
                            st.markdown(f"**ëª¨ë¸**: {model}")
                            st.markdown(response.get("answer", "ì‘ë‹µ ì—†ìŒ"))
                            
                            # í‰ê°€ ê²°ê³¼ê°€ ìˆê³  ìë™ í‰ê°€ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ í‘œì‹œ
                            if auto_eval and "evaluation" in response:
                                score = response.get("evaluation", {}).get("score", "í‰ê°€ ì—†ìŒ")
                                reason = response.get("evaluation", {}).get("reason", "ì´ìœ  ì—†ìŒ")
                                st.markdown(f"**í‰ê°€ ì ìˆ˜**: {score}/5")
                                st.markdown(f"**í‰ê°€ ì´ìœ **: {reason}")
                    else:
                        st.markdown("ëª¨ë¸ ì‘ë‹µ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.markdown("---")
        else:
            st.warning("í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        # ì¢…í•© ê²°ê³¼ í‘œì‹œ (ìë™ í‰ê°€ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
        if auto_eval and "summary" in results:
            st.subheader("ëª¨ë¸ í‰ê°€ ì¢…í•©")
            summary_data = []
            
            for model, stats in results.get("summary", {}).items():
                summary_data.append({
                    "ëª¨ë¸": model,
                    "í‰ê·  ì ìˆ˜": round(stats.get("avg_score", 0), 2),
                    "ì´ í‰ê°€ ìˆ˜": stats.get("total_evaluations", 0)
                })
            
            if summary_data:
                st.dataframe(pd.DataFrame(summary_data))

# ë””ë²„ê·¸ íƒ­ - ë©€í‹°ì¿¼ë¦¬ ë””ë²„ê¹…ì„ ìœ„í•œ íƒ­
with tab3:
    st.header("ë””ë²„ê·¸ ì •ë³´")
    
    # LangSmith ë””ë²„ê¹… ì„¹ì…˜ ì¶”ê°€
    if langsmith_enabled:
        with st.expander("ğŸ” LangSmith ì‹¤í–‰ ì¶”ì ", expanded=True):
            st.markdown("### LangSmith ì¶”ì  ì •ë³´")
            
            if st.session_state.run_ids:
                for run_type, run_id in st.session_state.run_ids.items():
                    st.markdown(f"**{run_type}**: `{run_id}`")
                    
                # LangSmith ëŒ€ì‹œë³´ë“œ ë§í¬ ì œê³µ
                st.markdown("LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì¶”ì  ì •ë³´ í™•ì¸í•˜ê¸°:")
                langsmith_url = "https://smith.langchain.com"
                st.markdown(f"[ëŒ€ì‹œë³´ë“œ ì—´ê¸°]({langsmith_url})")
            else:
                st.info("ì•„ì§ ì¶”ì ëœ ì‹¤í–‰ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì œì¶œí•˜ê±°ë‚˜ ìë™ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        st.warning("LangSmith ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # ë¡œê·¸ ì˜ì—­ ì¶”ê°€ - í„°ë¯¸ë„ ë¡œê·¸ë¥¼ ê°€ì¥ ë¨¼ì € í‘œì‹œ
    if st.session_state.raw_output:
        with st.expander("ğŸ“‹ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥", expanded=True):
            st.markdown("### í„°ë¯¸ë„ ì¶œë ¥ ë¡œê·¸")
            st.code(st.session_state.raw_output)
    
    # ë©€í‹°ì¿¼ë¦¬ ë””ë²„ê¹…
    if st.session_state.raw_output:
        with st.expander("ğŸ”„ ë©€í‹°ì¿¼ë¦¬ ë””ë²„ê·¸", expanded=False):
            st.markdown("### ë©€í‹°ì¿¼ë¦¬ ê´€ë ¨ ë¶€ë¶„")
            
            # ë©€í‹°ì¿¼ë¦¬ ê´€ë ¨ ë¶€ë¶„ ì¶”ì¶œ
            multi_query_debug = ""
            lines = st.session_state.raw_output.split('\n')
            in_multi_query_section = False
            
            for line in lines:
                if "í™•ì¥ ì§ˆì˜" in line or "ë©€í‹°ì¿¼ë¦¬" in line or "ìƒì„±ëœ ì¿¼ë¦¬" in line:
                    in_multi_query_section = True
                    multi_query_debug += f"**{line}**\n"
                elif in_multi_query_section and (line.strip() == "" or "ë¬¸ì„œ ê²€ìƒ‰" in line):
                    in_multi_query_section = False
                    multi_query_debug += "---\n"
                elif in_multi_query_section:
                    multi_query_debug += f"{line}\n"
            
            st.markdown(multi_query_debug)
    
    # ìë™ í…ŒìŠ¤íŠ¸ ë¡œê·¸ í‘œì‹œ (ìë™ í…ŒìŠ¤íŠ¸ê°€ ì‹¤í–‰ëœ ê²½ìš°)
    # ì„¸ì…˜ ìƒíƒœì— ìë™ í…ŒìŠ¤íŠ¸ ë¡œê·¸ ì¶”ê°€
    if 'auto_test_log' not in st.session_state:
        st.session_state.auto_test_log = ""
    
    if st.session_state.auto_test_log:
        with st.expander("ğŸ“‹ ìë™ í…ŒìŠ¤íŠ¸ ë¡œê·¸", expanded=False):
            st.markdown("### ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œê·¸")
            st.code(st.session_state.auto_test_log)

# í˜ì´ì§€ í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
## ì‚¬ìš© ë°©ë²•
1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ê³¼ ì„¤ì •ì„ ì„ íƒí•˜ì„¸ìš”.
2. 'ì§ˆë¬¸ ì‘ë‹µ' íƒ­ì—ì„œ ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê±°ë‚˜ 'ìë™ í…ŒìŠ¤íŠ¸' íƒ­ì—ì„œ ìë™ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.
3. ìë™ í…ŒìŠ¤íŠ¸ëŠ” ìµœê·¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
4. LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤í–‰ ê³¼ì •ê³¼ ê²°ê³¼ë¥¼ ì¶”ì í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ í•´ê²°
- Streamlit í˜ì´ì§€ê°€ í‘œì‹œë˜ì§€ ì•ŠëŠ” ê²½ìš°, ì½˜ì†”ì—ì„œ `streamlit run hwgi_streamlit_app.py` ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.
- Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (`http://localhost:11434`ì— ì ‘ì† ê°€ëŠ¥í•´ì•¼ í•¨)
- ë¡œì»¬ í™˜ê²½ì— Python ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
- ìë™ í‰ê°€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ gemma3:12b ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´ `ollama pull gemma3:12b` ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- LangSmith ì¶”ì ì„ ìœ„í•´ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ `LANGCHAIN_API_KEY`ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
""")

# ê¸°ë³¸ ì‹¤í–‰ ì •ë³´ë¥¼ í‘œì‹œ
st.sidebar.markdown("---")
st.sidebar.markdown("### ì‹œìŠ¤í…œ ì •ë³´")
st.sidebar.markdown("- Ollama ëª¨ë¸ ìë™ ê°ì§€ ë° ì‚¬ìš©")
st.sidebar.markdown("- ì‚¬ì—…ë³´ê³ ì„œ RAG ì‹œìŠ¤í…œ")
st.sidebar.markdown("- ì§ˆë¬¸ì€ í‘œì¤€ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤")
if langsmith_enabled:
    st.sidebar.markdown("- LangSmith ì¶”ì  í™œì„±í™”ë¨")
if auto_eval:
    st.sidebar.markdown("- ìë™ í‰ê°€ ëª¨ë“œ í™œì„±í™”ë¨")
else:
    st.sidebar.markdown("- ìë™ í‰ê°€ ëª¨ë“œ ë¹„í™œì„±í™”ë¨") 